from django.shortcuts import render, get_object_or_404, redirect
from django.contrib.auth.decorators import login_required, user_passes_test
from django.http import JsonResponse, HttpResponse
from django.views.decorators.csrf import csrf_exempt
from django.contrib import messages
from django.db.models import Q, Count, Avg
from django.core.paginator import Paginator
from django.utils import timezone
from datetime import datetime, timedelta
import json
import hashlib
import numpy as np
import pydicom
import os
import threading
import time
import re
import requests
try:
    import onnxruntime as ort
except Exception:
    ort = None
try:
    from transformers import AutoTokenizer, AutoModelForSequenceClassification
except Exception:
    AutoTokenizer = None
    AutoModelForSequenceClassification = None

from worklist.models import Study, DicomImage, Series
from accounts.models import User
from .models import (
    AIModel, AIAnalysis, AutoReportTemplate, AutoGeneratedReport,
    AITrainingData, AIPerformanceMetric, AIFeedback
)

# Comprehensive medical book references with topic mapping
MEDICAL_BOOK_REFERENCES = {
    'general': {
        'default': [
            {'title': "Brant & Helms – Fundamentals of Diagnostic Radiology", 'topic': 'General Principles'},
            {'title': "Grainger & Allison’s Diagnostic Radiology", 'topic': 'General Interpretation'},
        ]
    },
    'neuroradiology': {
        'stroke': [
            {'title': "Osborn’s Brain: Imaging, Pathology, and Anatomy", 'topic': 'Chapter 4: Vascular Disorders'},
            {'title': "Neuroradiology: The Requisites", 'topic': 'Stroke & Ischemia'},
        ],
        'hemorrhage': [
            {'title': "Osborn’s Brain", 'topic': 'Chapter 2: Intracranial Hemorrhage'},
            {'title': "Neuroradiology: The Requisites", 'topic': 'Trauma & Hemorrhage'},
        ],
        'tumor': [
             {'title': "Osborn’s Brain", 'topic': 'Chapter 12: Primary Brain Tumors'},
        ],
        'mass': [
             {'title': "Osborn’s Brain", 'topic': 'Chapter 1: Approach to Masses'},
        ],
        'default': [
            {'title': "Osborn’s Brain", 'topic': 'General Brain Imaging'},
        ]
    },
    'chest': {
        'pneumonia': [
             {'title': "Felson’s Principles of Chest Roentgenology", 'topic': 'Airspace Disease'},
             {'title': "Thoracic Imaging (Webb)", 'topic': 'Infection'},
        ],
        'pneumothorax': [
             {'title': "Felson’s Principles of Chest Roentgenology", 'topic': 'Pleural Disease'},
        ],
        'default': [
            {'title': "Felson’s Principles of Chest Roentgenology", 'topic': 'Chest Basics'},
        ]
    },
    'msk': {
        'fracture': [
            {'title': "Resnick’s Diagnosis of Bone and Joint Disorders", 'topic': 'Trauma & Fractures'},
        ],
        'default': [
            {'title': "Musculoskeletal MRI (Helms)", 'topic': 'General MSK'},
        ]
    },
    'emergency': {
        'default': [
            {'title': "Harris & Harris’ The Radiology of Emergency Medicine", 'topic': 'Trauma Overview'},
        ]
    }
}

def is_admin_or_radiologist(user):
    """Check if user is admin or radiologist"""
    return user.is_authenticated and (user.is_admin() or user.is_radiologist())

def _get_online_references(keywords, max_results=3):
    """
    Search for high-quality online references for approved users.
    Returns a list of dicts: {'title': str, 'url': str, 'source': str}
    """
    if not keywords:
        return []
    
    # Clean keywords for search
    search_query = " ".join(keywords[:3]) # Limit query length
    
    # Sources to prioritize
    sources = [
        'site:radiopaedia.org',
        'site:ncbi.nlm.nih.gov', # PubMed / PMC
        'site:merckmanuals.com/professional',
    ]
    
    full_query = f"{search_query} ({' OR '.join(sources)})"
    
    try:
        # Use DuckDuckGo HTML scrape (no API key needed, respectful of rate limits)
        ddg_url = 'https://duckduckgo.com/html/'
        params = {'q': full_query}
        headers = {'User-Agent': 'Mozilla/5.0 (compatible; NoctisPro/1.0; +https://example.com)'}
        
        resp = requests.post(ddg_url, data=params, headers=headers, timeout=5)
        
        results = []
        if resp.ok:
            for m in re.finditer(r'<a[^>]+class="result__a"[^>]*href="([^"]+)"[^>]*>(.*?)</a>', resp.text, re.I | re.S):
                url = m.group(1)
                title_raw = re.sub('<[^<]+?>', '', m.group(2))
                title = re.sub(r'\s+', ' ', title_raw).strip()
                
                # Determine source label
                source_label = 'Web'
                if 'radiopaedia.org' in url: source_label = 'Radiopaedia'
                elif 'ncbi.nlm.nih.gov' in url: source_label = 'PubMed/NCBI'
                elif 'merckmanuals' in url: source_label = 'Merck Manual'
                
                if url and title:
                    results.append({'title': title, 'url': url, 'source': source_label})
                
                if len(results) >= max_results:
                    break
        return results
    except Exception:
        # Fail gracefully
        return []

@login_required
def ai_dashboard(request):
    """AI analysis dashboard with comprehensive overview"""
    user = request.user
    
    # Get AI models statistics
    total_models = AIModel.objects.filter(is_active=True).count()
    active_analyses = AIAnalysis.objects.filter(status__in=['pending', 'processing']).count()
    completed_today = AIAnalysis.objects.filter(
        completed_at__date=timezone.now().date(),
        status='completed'
    ).count()
    total_analyses = AIAnalysis.objects.count()
    processing_queue = active_analyses

    # Average accuracy from available performance metrics (percentage)
    avg_accuracy = (
        AIPerformanceMetric.objects.filter(ai_model__is_active=True)
        .aggregate(avg=Avg('accuracy'))
        .get('avg')
    )
    accuracy_rate = round((avg_accuracy or 0) * 100, 1)
    
    # Get recent analyses
    if user.is_facility_user():
        recent_analyses = AIAnalysis.objects.filter(
            study__facility=user.facility
        ).select_related('study', 'ai_model').order_by('-requested_at')[:10]
    else:
        recent_analyses = AIAnalysis.objects.select_related(
            'study', 'ai_model'
        ).order_by('-requested_at')[:10]
    
    # Get pending auto-reports
    if user.is_radiologist() or user.is_admin():
        pending_reports = AutoGeneratedReport.objects.filter(
            review_status='pending'
        ).select_related('study', 'ai_analysis').order_by('-generated_at')[:5]
    else:
        pending_reports = []
    
    # Get model performance summary
    model_performance = []
    for model in AIModel.objects.filter(is_active=True)[:5]:
        latest_metric = model.performance_metrics.first()
        model_performance.append({
            'model': model,
            'accuracy': latest_metric.accuracy if latest_metric else 0,
            'total_analyses': model.total_analyses,
            'avg_time': model.avg_processing_time
        })
    
    context = {
        # Template-friendly dashboard stats
        'total_analyses': total_analyses,
        'active_models': total_models,
        'processing_queue': processing_queue,
        'accuracy_rate': accuracy_rate,

        'total_models': total_models,
        'active_analyses': active_analyses,
        'completed_today': completed_today,
        'recent_analyses': recent_analyses,
        'pending_reports': pending_reports,
        'model_performance': model_performance,
        'user': user,
    }
    
    return render(request, 'ai_analysis/dashboard.html', context)


@login_required
@user_passes_test(is_admin_or_radiologist)
def study_picker(request):
    """Pick a study to run AI analysis on."""
    user = request.user

    studies = Study.objects.select_related('patient', 'modality', 'facility').order_by('-upload_date')

    # Facility scoping
    if user.is_facility_user():
        studies = studies.filter(facility=user.facility)

    q = (request.GET.get('q') or '').strip()
    if q:
        studies = studies.filter(
            Q(accession_number__icontains=q)
            | Q(patient__first_name__icontains=q)
            | Q(patient__last_name__icontains=q)
            | Q(patient__patient_id__icontains=q)
        )

    paginator = Paginator(studies, 25)
    page_number = request.GET.get('page')
    studies_page = paginator.get_page(page_number)

    return render(
        request,
        'ai_analysis/study_picker.html',
        {
            'studies': studies_page,
            'query': q,
        },
    )

@login_required
@csrf_exempt
def analyze_study(request, study_id):
    """Run AI analysis on study"""
    study = get_object_or_404(Study, id=study_id)
    user = request.user
    
    # Check permissions
    if user.is_facility_user() and study.facility != user.facility:
        return JsonResponse({'error': 'Permission denied'}, status=403)
    
    if request.method == 'POST':
        # Only administrators or radiologists can initiate new AI analyses
        if not is_admin_or_radiologist(user):
            return JsonResponse({'error': 'Only administrators or radiologists can start AI analyses'}, status=403)
        try:
            # Get selected AI models
            model_ids = request.POST.getlist('ai_models')
            priority = request.POST.get('priority', 'normal')
            
            if not model_ids:
                return JsonResponse({'error': 'Please select at least one AI model'}, status=400)
            
            # Create analyses for each selected model
            analyses = []
            for model_id in model_ids:
                ai_model = get_object_or_404(AIModel, id=model_id, is_active=True)
                
                # Check if analysis already exists
                existing = AIAnalysis.objects.filter(
                    study=study,
                    ai_model=ai_model,
                    status__in=['pending', 'processing', 'completed']
                ).first()
                
                if existing:
                    continue
                
                # Create new analysis
                analysis = AIAnalysis.objects.create(
                    study=study,
                    ai_model=ai_model,
                    priority=priority,
                    status='pending'
                )
                analyses.append(analysis)
            
            # Start processing in background
            if analyses:
                threading.Thread(
                    target=process_ai_analyses,
                    args=(analyses,),
                    daemon=True
                ).start()
            
            return JsonResponse({
                'success': True,
                'message': f'Started AI analysis with {len(analyses)} models',
                'analysis_ids': [a.id for a in analyses]
            })
            
        except Exception as e:
            return JsonResponse({'error': str(e)}, status=500)
    
    # GET request - show analysis form
    available_models = []
    if is_admin_or_radiologist(user):
        available_models = AIModel.objects.filter(
            is_active=True,
            modality__in=[study.modality.code, 'ALL']
        )
    
    # Get existing analyses
    existing_analyses = AIAnalysis.objects.filter(
        study=study
    ).select_related('ai_model').order_by('-requested_at')
    
    context = {
        'study': study,
        'available_models': available_models,
        'existing_analyses': existing_analyses,
    }
    
    return render(request, 'ai_analysis/analyze_study.html', context)

@login_required
@csrf_exempt
def api_analysis_status(request, analysis_id):
    """Get analysis status and progress"""
    analysis = get_object_or_404(AIAnalysis, id=analysis_id)
    user = request.user
    
    # Check permissions
    if user.is_facility_user() and analysis.study.facility != user.facility:
        return JsonResponse({'error': 'Permission denied'}, status=403)
    
    progress_percentage = 0
    if analysis.status == 'completed':
        progress_percentage = 100
    elif analysis.status == 'processing':
        # Estimate progress based on processing time
        if analysis.started_at:
            elapsed = (timezone.now() - analysis.started_at).total_seconds()
            estimated_total = analysis.ai_model.avg_processing_time or 60
            progress_percentage = min(90, (elapsed / estimated_total) * 100)
    
    # Only administrators/radiologists get full detailed analysis
    clinician = is_admin_or_radiologist(user)
    data = {
        'id': analysis.id,
        'status': analysis.status,
        'progress_percentage': round(progress_percentage, 2),
        'confidence_score': analysis.confidence_score,
        'requested_at': analysis.requested_at.isoformat(),
        'completed_at': analysis.completed_at.isoformat() if analysis.completed_at else None,
        'ai_model': {
            'name': analysis.ai_model.name,
            'version': analysis.ai_model.version,
            'type': analysis.ai_model.model_type
        }
    }
    if clinician:
        data.update({
            'findings': analysis.findings,
            'abnormalities_detected': analysis.abnormalities_detected,
            'measurements': analysis.measurements,
            'processing_time': analysis.processing_time,
            'error_message': analysis.error_message,
        })
        
        # Add real-time online references if measurements contain findings/keywords
        # This is done on-demand to ensure "real-time" aspect for viewing
        if analysis.status == 'completed' and analysis.measurements:
            refs = analysis.measurements.get('reference_suggestions', [])
            keywords = []
            
            # Extract keywords from findings labels
            abnormalities = analysis.abnormalities_detected or []
            for a in abnormalities:
                label = _normalize_abnormality_label(a).lower()
                if label: 
                    # simple heuristic to clean label
                    clean = re.sub(r'suspicion|possible|probable', '', label).strip()
                    if clean: keywords.append(clean)
            
            # Fetch real-time references if we have keywords
            if keywords:
                # Cache key to prevent spamming searches on every poll
                online_refs = analysis.measurements.get('online_references')
                if not online_refs:
                    # Fetch and save
                    online_refs = _get_online_references(keywords)
                    if online_refs:
                        # Update DB with new online refs
                        analysis.measurements['online_references'] = online_refs
                        analysis.save(update_fields=['measurements'])
                
                data['online_references'] = online_refs
                
    else:
        # Minimal, non-intrusive preliminary summary for non-clinician roles
        data.update({
            'summary': 'Preliminary AI review complete' if analysis.status == 'completed' else 'AI review in progress',
        })
    
    return JsonResponse(data)


@login_required
@csrf_exempt
def api_analyze_series(request, series_id):
    """
    DICOM viewer integration endpoint.
    Runs a quick (synchronous) AI analysis for a given Series and returns a simple
    findings list for UI display.
    """
    if request.method != 'POST':
        return JsonResponse({'success': False, 'error': 'Method not allowed'}, status=405)

    user = request.user
    series = get_object_or_404(Series, id=series_id)
    study = series.study

    # Facility permissions
    if user.is_facility_user() and study.facility != user.facility:
        return JsonResponse({'success': False, 'error': 'Permission denied'}, status=403)

    # Only clinicians/admins can initiate AI runs
    if not is_admin_or_radiologist(user):
        return JsonResponse(
            {'success': False, 'error': 'Only administrators or radiologists can start AI analyses'},
            status=403,
        )

    # Pick one suitable active model for this modality
    modality_code = getattr(study.modality, 'code', None)
    ai_model = (
        AIModel.objects.filter(is_active=True, modality__in=[modality_code, 'ALL'])
        .order_by('model_type', '-created_at')
        .first()
    )
    if not ai_model:
        return JsonResponse(
            {'success': False, 'error': f'No active AI models available for modality {modality_code}'},
            status=400,
        )

    # Create and run analysis synchronously (keeps the viewer UX simple)
    analysis = AIAnalysis.objects.create(
        study=study,
        ai_model=ai_model,
        priority='normal',
        status='pending',
    )

    try:
        analysis.start_processing()
        results = simulate_ai_analysis(analysis)
        analysis.complete_analysis(results)
        try:
            _apply_ai_triage(analysis)
        except Exception:
            pass

        conf = float(analysis.confidence_score or 0.0)

        findings_list = []
        if analysis.findings:
            findings_list.append(
                {
                    'type': ai_model.name,
                    'description': analysis.findings,
                    'confidence': conf,
                }
            )
        for abn in (analysis.abnormalities_detected or []):
            label = _normalize_abnormality_label(abn)
            if label:
                findings_list.append(
                    {
                        'type': 'Abnormality',
                        'description': label,
                        'confidence': conf,
                    }
                )

        return JsonResponse(
            {
                'success': True,
                'analysis_id': analysis.id,
                'findings': findings_list,
                'annotations': [],
                'measurements': analysis.measurements or {},
            }
        )
    except Exception as e:
        analysis.status = 'failed'
        analysis.error_message = str(e)
        analysis.save(update_fields=['status', 'error_message'])
        return JsonResponse({'success': False, 'error': str(e)}, status=500)

@login_required
@user_passes_test(is_admin_or_radiologist)
@csrf_exempt
def generate_auto_report(request, study_id):
    """Generate automatic report from AI analysis"""
    study = get_object_or_404(Study, id=study_id)
    user = request.user
    
    # Check facility permissions
    if user.is_facility_user() and study.facility != user.facility:
        return JsonResponse({'error': 'Permission denied'}, status=403)
    
    try:
        # Get completed AI analyses for this study
        analyses = AIAnalysis.objects.filter(
            study=study,
            status='completed'
        ).select_related('ai_model')
        
        if not analyses:
            return JsonResponse({'error': 'No completed AI analyses found for this study'}, status=400)
        
        # Find appropriate template
        template = AutoReportTemplate.objects.filter(
            modality=study.modality.code,
            body_part__icontains=study.body_part,
            is_active=True
        ).first()
        
        if not template:
            # Use generic template
            template = AutoReportTemplate.objects.filter(
                modality=study.modality.code,
                is_active=True
            ).first()
        
        if not template:
            return JsonResponse({'error': 'No suitable report template found'}, status=400)
        
        # Generate report content
        report_data = generate_report_content(study, analyses, template)
        
        # Create auto-generated report
        auto_report = AutoGeneratedReport.objects.create(
            study=study,
            template=template,
            ai_analysis=analyses.first(),  # Primary analysis
            generated_findings=report_data['findings'],
            generated_impression=report_data['impression'],
            generated_recommendations=report_data['recommendations'],
            overall_confidence=report_data['confidence'],
            requires_review=report_data['confidence'] < template.confidence_threshold
        )
        
        return JsonResponse({
            'success': True,
            'report_id': auto_report.id,
            'findings': auto_report.generated_findings,
            'impression': auto_report.generated_impression,
            'recommendations': auto_report.generated_recommendations,
            'confidence': auto_report.overall_confidence,
            'requires_review': auto_report.requires_review
        })
        
    except Exception as e:
        return JsonResponse({'error': f'Error generating report: {str(e)}'}, status=500)

@login_required
@user_passes_test(is_admin_or_radiologist)
def review_auto_report(request, report_id):
    """Review and approve/modify auto-generated report"""
    auto_report = get_object_or_404(AutoGeneratedReport, id=report_id)
    user = request.user
    
    # Check permissions
    if user.is_facility_user() and auto_report.study.facility != user.facility:
        messages.error(request, 'Permission denied')
        return redirect('ai_analysis:ai_dashboard')
    
    if request.method == 'POST':
        action = request.POST.get('action')
        
        if action == 'approve':
            auto_report.review_status = 'approved'
            auto_report.reviewed_by = user
            auto_report.reviewed_at = timezone.now()
            auto_report.review_comments = request.POST.get('comments', '')
            auto_report.save()
            
            # Create final report (when reports app is available)
            # auto_report.approve_and_create_report(user)
            
            messages.success(request, 'Auto-generated report approved successfully')
            
        elif action == 'modify':
            auto_report.generated_findings = request.POST.get('findings')
            auto_report.generated_impression = request.POST.get('impression')
            auto_report.generated_recommendations = request.POST.get('recommendations')
            auto_report.review_status = 'modified'
            auto_report.reviewed_by = user
            auto_report.reviewed_at = timezone.now()
            auto_report.review_comments = request.POST.get('comments', '')
            auto_report.save()
            
            messages.success(request, 'Auto-generated report modified and approved')
            
        elif action == 'reject':
            auto_report.review_status = 'rejected'
            auto_report.reviewed_by = user
            auto_report.reviewed_at = timezone.now()
            auto_report.review_comments = request.POST.get('comments', '')
            auto_report.save()
            
            messages.success(request, 'Auto-generated report rejected')
        
        return redirect('ai_analysis:ai_dashboard')
    
    # GET request - show review form
    context = {
        'auto_report': auto_report,
        'study': auto_report.study,
        'ai_analysis': auto_report.ai_analysis,
    }
    
    return render(request, 'ai_analysis/review_auto_report.html', context)

@login_required
@csrf_exempt
def api_ai_feedback(request, analysis_id):
    """Submit feedback on AI analysis"""
    analysis = get_object_or_404(AIAnalysis, id=analysis_id)
    user = request.user
    
    # Check permissions
    if user.is_facility_user() and analysis.study.facility != user.facility:
        return JsonResponse({'error': 'Permission denied'}, status=403)
    
    if request.method == 'POST':
        try:
            data = json.loads(request.body)
            
            feedback = AIFeedback.objects.create(
                ai_analysis=analysis,
                user=user,
                feedback_type=data.get('feedback_type'),
                rating=data.get('rating'),
                comments=data.get('comments', ''),
                incorrect_findings=data.get('incorrect_findings', []),
                missed_findings=data.get('missed_findings', []),
                suggestions=data.get('suggestions', '')
            )
            
            return JsonResponse({
                'success': True,
                'feedback_id': feedback.id,
                'message': 'Feedback submitted successfully'
            })
            
        except Exception as e:
            return JsonResponse({'error': str(e)}, status=500)
    
    return JsonResponse({'error': 'Method not allowed'}, status=405)

@login_required
@user_passes_test(is_admin_or_radiologist)
def model_management(request):
    """AI model management interface"""
    models = AIModel.objects.all().order_by('-created_at')
    
    # Search and filtering
    search_query = request.GET.get('search', '')
    if search_query:
        models = models.filter(
            Q(name__icontains=search_query) |
            Q(description__icontains=search_query) |
            Q(modality__icontains=search_query)
        )
    
    model_type_filter = request.GET.get('model_type', '')
    if model_type_filter:
        models = models.filter(model_type=model_type_filter)
    
    # Pagination
    paginator = Paginator(models, 20)
    page_number = request.GET.get('page')
    models_page = paginator.get_page(page_number)
    
    context = {
        'models': models_page,
        'search_query': search_query,
        'model_type_filter': model_type_filter,
        'model_types': AIModel.MODEL_TYPES,
    }
    
    return render(request, 'ai_analysis/model_management.html', context)

@login_required
@csrf_exempt
def api_realtime_analyses(request):
    """Get real-time AI analysis updates"""
    user = request.user
    
    # Get timestamp from request
    last_update = request.GET.get('last_update')
    
    try:
        if last_update:
            last_update_time = timezone.datetime.fromisoformat(last_update.replace('Z', '+00:00'))
        else:
            last_update_time = timezone.now() - timezone.timedelta(minutes=5)
    except:
        last_update_time = timezone.now() - timezone.timedelta(minutes=5)
    
    # Get analyses updated since last check
    if user.is_facility_user():
        analyses = AIAnalysis.objects.filter(
            study__facility=user.facility,
            requested_at__gt=last_update_time
        ).select_related('study', 'ai_model').order_by('-requested_at')[:20]
    else:
        analyses = AIAnalysis.objects.filter(
            requested_at__gt=last_update_time
        ).select_related('study', 'ai_model').order_by('-requested_at')[:20]
    
    clinician = is_admin_or_radiologist(user)
    analyses_data = []
    for analysis in analyses:
        item = {
            'id': analysis.id,
            'study_id': analysis.study.id,
            'accession_number': analysis.study.accession_number,
            'patient_name': analysis.study.patient.full_name,
            'ai_model': analysis.ai_model.name,
            'status': analysis.status,
            'priority': analysis.priority,
            'requested_at': analysis.requested_at.isoformat(),
            'completed_at': analysis.completed_at.isoformat() if analysis.completed_at else None,
        }
        if clinician:
            item['confidence_score'] = analysis.confidence_score
        analyses_data.append(item)
    
    return JsonResponse({
        'analyses': analyses_data,
        'timestamp': timezone.now().isoformat(),
        'count': len(analyses_data)
    })

@login_required
@user_passes_test(lambda u: u.is_admin())
def ai_reporting_dashboard(request):
    """Comprehensive AI reporting dashboard"""
    # Get date range from request
    end_date = timezone.now().date()
    start_date = end_date - timedelta(days=30)
    
    date_filter = request.GET.get('date_range', '30d')
    if date_filter == '7d':
        start_date = end_date - timedelta(days=7)
    elif date_filter == '90d':
        start_date = end_date - timedelta(days=90)
    elif date_filter == '1y':
        start_date = end_date - timedelta(days=365)
    
    # Overall statistics
    total_analyses = AIAnalysis.objects.filter(
        requested_at__date__gte=start_date,
        requested_at__date__lte=end_date
    ).count()
    
    completed_analyses = AIAnalysis.objects.filter(
        requested_at__date__gte=start_date,
        requested_at__date__lte=end_date,
        status='completed'
    ).count()
    
    failed_analyses = AIAnalysis.objects.filter(
        requested_at__date__gte=start_date,
        requested_at__date__lte=end_date,
        status='failed'
    ).count()
    
    # Success rate
    success_rate = (completed_analyses / total_analyses * 100) if total_analyses > 0 else 0
    
    # Average processing time
    avg_processing_time = AIAnalysis.objects.filter(
        requested_at__date__gte=start_date,
        requested_at__date__lte=end_date,
        status='completed',
        processing_time__isnull=False
    ).aggregate(Avg('processing_time'))['processing_time__avg'] or 0
    
    # Model performance breakdown
    model_performance = []
    for model in AIModel.objects.filter(is_active=True):
        model_analyses = AIAnalysis.objects.filter(
            ai_model=model,
            requested_at__date__gte=start_date,
            requested_at__date__lte=end_date
        )
        
        total = model_analyses.count()
        completed = model_analyses.filter(status='completed').count()
        failed = model_analyses.filter(status='failed').count()
        avg_confidence = model_analyses.filter(
            status='completed',
            confidence_score__isnull=False
        ).aggregate(Avg('confidence_score'))['confidence_score__avg'] or 0
        
        model_performance.append({
            'model': model,
            'total_analyses': total,
            'completed': completed,
            'failed': failed,
            'success_rate': (completed / total * 100) if total > 0 else 0,
            'avg_confidence': round(avg_confidence, 3),
            'avg_processing_time': model.avg_processing_time or 0
        })
    
    # Auto-report statistics
    total_auto_reports = AutoGeneratedReport.objects.filter(
        generated_at__date__gte=start_date,
        generated_at__date__lte=end_date
    ).count()
    
    approved_reports = AutoGeneratedReport.objects.filter(
        generated_at__date__gte=start_date,
        generated_at__date__lte=end_date,
        review_status='approved'
    ).count()
    
    pending_reports = AutoGeneratedReport.objects.filter(
        review_status='pending'
    ).count()
    
    # Daily analysis trends
    daily_trends = []
    current_date = start_date
    while current_date <= end_date:
        daily_count = AIAnalysis.objects.filter(
            requested_at__date=current_date
        ).count()
        daily_trends.append({
            'date': current_date.isoformat(),
            'count': daily_count
        })
        current_date += timedelta(days=1)
    
    # Top performing models
    top_models = sorted(model_performance, key=lambda x: x['success_rate'], reverse=True)[:5]
    
    # Recent feedback
    recent_feedback = AIFeedback.objects.filter(
        created_at__date__gte=start_date
    ).select_related('ai_analysis__ai_model', 'user').order_by('-created_at')[:10]
    
    context = {
        'total_analyses': total_analyses,
        'completed_analyses': completed_analyses,
        'failed_analyses': failed_analyses,
        'success_rate': round(success_rate, 2),
        'avg_processing_time': round(avg_processing_time, 2),
        'model_performance': model_performance,
        'total_auto_reports': total_auto_reports,
        'approved_reports': approved_reports,
        'pending_reports': pending_reports,
        'daily_trends': daily_trends,
        'top_models': top_models,
        'recent_feedback': recent_feedback,
        'date_filter': date_filter,
        'start_date': start_date,
        'end_date': end_date,
    }
    
    return render(request, 'ai_analysis/reporting_dashboard.html', context)

@login_required
@user_passes_test(lambda u: u.is_admin())
def verify_ai_models(request):
    """Verify that all AI models are working correctly"""
    verification_results = []
    
    # Get all active AI models
    models = AIModel.objects.filter(is_active=True)
    
    for model in models:
        result = {
            'model': model,
            'status': 'unknown',
            'last_test': None,
            'test_results': {},
            'issues': []
        }
        
        # Check if model files exist
        if not os.path.exists(model.model_file_path):
            result['issues'].append('Model file not found')
            result['status'] = 'error'
        
        # Check recent analyses
        recent_analyses = AIAnalysis.objects.filter(
            ai_model=model,
            requested_at__gte=timezone.now() - timedelta(days=7)
        )
        
        if recent_analyses.exists():
            completed = recent_analyses.filter(status='completed').count()
            failed = recent_analyses.filter(status='failed').count()
            total = recent_analyses.count()
            
            success_rate = (completed / total * 100) if total > 0 else 0
            
            result['test_results'] = {
                'total_tests': total,
                'completed': completed,
                'failed': failed,
                'success_rate': round(success_rate, 2)
            }
            
            if success_rate >= 95:
                result['status'] = 'excellent'
            elif success_rate >= 85:
                result['status'] = 'good'
            elif success_rate >= 70:
                result['status'] = 'warning'
            else:
                result['status'] = 'error'
                result['issues'].append(f'Low success rate: {success_rate:.1f}%')
        else:
            result['status'] = 'untested'
            result['issues'].append('No recent test data available')
        
        # Check performance metrics
        latest_metric = model.performance_metrics.first()
        if latest_metric:
            result['last_test'] = latest_metric.evaluation_date
            if latest_metric.accuracy < 0.8:
                result['issues'].append(f'Low accuracy: {latest_metric.accuracy:.3f}')
        else:
            result['issues'].append('No performance metrics available')
        
        verification_results.append(result)
    
    # Overall system status
    statuses = [r['status'] for r in verification_results]
    if 'error' in statuses:
        overall_status = 'error'
    elif 'warning' in statuses:
        overall_status = 'warning'
    elif 'untested' in statuses:
        overall_status = 'warning'
    else:
        overall_status = 'good'
    
    context = {
        'verification_results': verification_results,
        'overall_status': overall_status,
        'total_models': len(verification_results),
        'error_count': statuses.count('error'),
        'warning_count': statuses.count('warning') + statuses.count('untested'),
        'good_count': statuses.count('good') + statuses.count('excellent'),
    }
    
    return render(request, 'ai_analysis/model_verification.html', context)

@login_required
@user_passes_test(lambda u: u.is_admin())
@csrf_exempt
def run_model_test(request, model_id):
    """Run a test on a specific AI model"""
    model = get_object_or_404(AIModel, id=model_id)
    
    if request.method == 'POST':
        try:
            # Get a test study for this modality
            test_study = Study.objects.filter(
                modality__code=model.modality
            ).first()
            
            if not test_study:
                return JsonResponse({
                    'success': False,
                    'error': f'No test studies available for modality {model.modality}'
                })
            
            # Create a test analysis
            test_analysis = AIAnalysis.objects.create(
                study=test_study,
                ai_model=model,
                priority='high',
                status='pending'
            )
            
            # Run the analysis in background
            threading.Thread(
                target=process_ai_analyses,
                args=([test_analysis],),
                daemon=True
            ).start()
            
            return JsonResponse({
                'success': True,
                'analysis_id': test_analysis.id,
                'message': f'Test started for {model.name}'
            })
            
        except Exception as e:
            return JsonResponse({
                'success': False,
                'error': str(e)
            })
    
    return JsonResponse({'error': 'Method not allowed'}, status=405)

def process_ai_analyses(analyses):
    """Background task to process AI analyses"""
    for analysis in analyses:
        try:
            analysis.start_processing()
            
            # Simulate AI processing (replace with actual AI model inference)
            results = simulate_ai_analysis(analysis)
            
            # Complete the analysis
            analysis.complete_analysis(results)

            # Apply AI triage/flagging to the parent study (severity → study.priority)
            try:
                _apply_ai_triage(analysis)
            except Exception:
                # Never fail the background worker due to triage/notification issues
                pass
            
            # Update model statistics
            model = analysis.ai_model
            model.total_analyses += 1
            if analysis.processing_time:
                # Update average processing time
                if model.avg_processing_time > 0:
                    model.avg_processing_time = (
                        model.avg_processing_time + analysis.processing_time
                    ) / 2
                else:
                    model.avg_processing_time = analysis.processing_time
            model.save()
            
        except Exception as e:
            analysis.status = 'failed'
            analysis.error_message = str(e)
            analysis.save()

_PRIORITY_RANK = {'low': 0, 'normal': 1, 'high': 2, 'urgent': 3}


def _normalize_abnormality_label(item) -> str:
    """Best-effort normalization for abnormality entries (dicts/strings)."""
    try:
        if isinstance(item, dict):
            for key in ('label', 'type', 'name', 'finding'):
                val = item.get(key)
                if isinstance(val, str) and val.strip():
                    return val.strip()
            return json.dumps(item, sort_keys=True)
        return str(item).strip()
    except Exception:
        return ''


def _compute_ai_triage(abnormalities, confidence: float) -> dict:
    """
    Compute a triage level + score from AI outputs.
    This is intentionally conservative: it upgrades but never auto-downgrades a study.
    """
    conf = float(confidence or 0.0)
    labels = [(_normalize_abnormality_label(a) or '').lower() for a in (abnormalities or [])]
    labels = [l for l in labels if l]

    # "Urgent" keywords: conditions where expedited review is typically warranted.
    urgent_keywords = (
        'intracranial hemorrhage', 'hemorrhage', 'ich', 'stroke', 'infarct',
        'pneumothorax', 'tension pneumothorax', 'pulmonary embolism', 'embolism',
        'aortic dissection', 'free air', 'perforation'
    )
    # "High" keywords: important findings that should be prioritized but may be less immediately time-critical.
    high_keywords = (
        'fracture', 'consolidation', 'pneumonia', 'large effusion', 'mass', 'tumor',
        'significant stenosis'
    )
    # Trauma heuristics: treat explicit trauma mechanisms/contexts as higher urgency.
    trauma_context_keywords = (
        'trauma', 'mvc', 'rt a', 'rta', 'fall', 'assault', 'gunshot', 'stab', 'blunt', 'polytrauma'
    )
    trauma_finding_keywords = (
        'fracture', 'dislocation', 'hemorrhage', 'bleed', 'laceration',
        'pneumothorax', 'hemothorax', 'contusion', 'solid organ injury', 'free fluid'
    )

    max_hint = 'normal'
    reason = 'no_abnormalities'
    if any(any(k in l for k in urgent_keywords) for l in labels):
        max_hint = 'urgent'
        reason = 'urgent_keyword'
    elif any(any(k in l for k in trauma_finding_keywords) for l in labels) and (
        any(any(k in l for k in trauma_context_keywords) for l in labels)
    ):
        # If a model explicitly emits trauma context + trauma finding, treat as urgent.
        max_hint = 'urgent'
        reason = 'trauma_keyword'
    elif any(any(k in l for k in high_keywords) for l in labels):
        max_hint = 'high'
        reason = 'high_keyword'
    elif labels:
        max_hint = 'normal'
        reason = 'abnormality_present'

    base = {'low': 0.15, 'normal': 0.35, 'high': 0.70, 'urgent': 1.0}.get(max_hint, 0.35)
    score = min(1.0, (base * 0.6) + (conf * 0.4))

    if max_hint == 'urgent' or score >= 0.85:
        level = 'urgent'
    elif max_hint == 'high' or score >= 0.65:
        level = 'high'
    elif score <= 0.25 and not labels:
        level = 'low'
    else:
        level = 'normal'

    flagged = level in ('high', 'urgent') and conf >= 0.55
    return {
        'triage_level': level,
        'triage_score': round(score, 3),
        'flagged': bool(flagged),
        'reason': reason,
        'abnormalities_count': len(labels),
    }


def _upgrade_study_priority(study: Study, new_priority: str) -> bool:
    """Upgrade the study priority if the new priority is more severe."""
    try:
        cur = (study.priority or 'normal').lower()
        nxt = (new_priority or 'normal').lower()
        if _PRIORITY_RANK.get(nxt, 1) > _PRIORITY_RANK.get(cur, 1):
            study.priority = nxt
            study.save(update_fields=['priority', 'last_updated'])
            return True
        return False
    except Exception:
        return False


def _notify_ai_triage(analysis: AIAnalysis, triage: dict) -> None:
    """Create a notification for radiologists/admins when AI upgrades triage."""
    try:
        from notifications.models import Notification, NotificationType
        from notifications.models import NotificationPreference
        from notifications import services as notify_services

        study = analysis.study
        facility = getattr(study, 'facility', None)
        triage_level = triage.get('triage_level', 'normal')
        triage_score = triage.get('triage_score', 0)

        notif_type, _ = NotificationType.objects.get_or_create(
            code='ai_triage',
            defaults={
                'name': 'AI Triage Flag',
                'description': 'AI flagged a study for priority review',
                'is_system': True,
                'default_priority': 'high',
            },
        )

        # Radiologists at the same facility, plus all admins (facility optional).
        recipients = User.objects.filter(Q(role='radiologist') | Q(role='admin'))
        if facility:
            recipients = recipients.filter(Q(role='admin') | Q(facility=facility))

        title = f"AI flagged study {study.accession_number} ({triage_level.upper()})"
        msg = (
            f"AI triage level: {triage_level.upper()} (score {triage_score}). "
            f"Please review the study promptly. Findings: {analysis.findings[:200]}"
        )
        
        # Add references if present in analysis measurements
        if analysis.measurements and 'reference_suggestions' in analysis.measurements:
            refs = analysis.measurements['reference_suggestions']
            if refs:
                # Simplify to title + topic for SMS/Notification brevity
                ref_texts = [f"{r.get('title')} ({r.get('topic')})" for r in refs if isinstance(r, dict)]
                if not ref_texts: # Fallback if old format
                    ref_texts = [r for r in refs if isinstance(r, str)]
                msg += " | Refs: " + "; ".join(ref_texts[:2])

        action_url = f"/worklist/study/{study.id}/"
        # Dedupe key prevents duplicate alerts per recipient/triage level.
        dedupe_key = f"ai_triage:{study.id}:{analysis.id}:{triage_level}"
        
        for recipient in recipients:
            # Check for offline status (last_login > 15 mins ago or None)
            is_offline = True
            if recipient.last_login:
                if (timezone.now() - recipient.last_login).total_seconds() < 900:
                    is_offline = False
            
            # Avoid duplicating the same alert repeatedly.
            if Notification.objects.filter(
                recipient=recipient,
                notification_type=notif_type,
                data__dedupe_key=dedupe_key,
            ).exists():
                continue

            notif = Notification.objects.create(
                notification_type=notif_type,
                recipient=recipient,
                sender=None,
                title=title,
                message=msg,
                priority=triage_level if triage_level in _PRIORITY_RANK else 'high',
                study=study,
                facility=facility,
                action_url=action_url,
                data={
                    'study_id': study.id,
                    'analysis_id': analysis.id,
                    'triage': triage,
                    'dedupe_key': dedupe_key,
                },
            )

            # Notification Logic based on Urgency and Presence
            # Urgent -> Always Call/SMS if configured.
            # High -> Call/SMS if configured AND user is offline.
            # Normal -> Web notification only (handled by creation above).
            
            should_notify_out_of_band = False
            if triage_level == 'urgent':
                should_notify_out_of_band = True
            elif triage_level == 'high' and is_offline:
                should_notify_out_of_band = True

            if should_notify_out_of_band:
                try:
                    pref = NotificationPreference.objects.filter(user=recipient).first()
                    # Default to SMS if not specified for urgent alerts
                    method = (getattr(pref, 'preferred_method', None) or 'sms').lower()
                    if method == 'web': 
                        method = 'sms' # Force SMS for urgent offline alerts if web was default
                    
                    to_number = (getattr(recipient, 'phone', None) or '').strip()
                    if not to_number:
                        continue
                        
                    if method == 'sms':
                        notify_services.send_sms(
                            to_number,
                            f"[CRITICAL] {title}. Open: {action_url}",
                        )
                    elif method == 'call':
                        notify_services.place_call(
                            to_number,
                            f"Critical AI alert. {title}. Please log in to review immediately.",
                        )
                except Exception:
                    # Best-effort only: web notification remains
                    pass
    except Exception:
        # Best-effort only
        return


def _apply_ai_triage(analysis: AIAnalysis) -> None:
    """
    Persist triage info to the analysis, upgrade Study.priority if needed,
    and notify radiologists/admins on upgrade.
    """
    triage = _compute_ai_triage(analysis.abnormalities_detected, analysis.confidence_score or 0.0)

    # Persist triage metadata on the analysis (no schema changes required).
    try:
        measurements = analysis.measurements or {}
        if not isinstance(measurements, dict):
            measurements = {}
        measurements.update({
            'triage_level': triage.get('triage_level'),
            'triage_score': triage.get('triage_score'),
            'triage_flagged': triage.get('flagged'),
            'triage_reason': triage.get('reason'),
        })
        
        # Persist reference suggestions based on modality/body part and findings
        try:
            suggested_refs = []
            
            # Helper to add refs
            def add_refs_for_key(category, key):
                if category in MEDICAL_BOOK_REFERENCES and key in MEDICAL_BOOK_REFERENCES[category]:
                    suggested_refs.extend(MEDICAL_BOOK_REFERENCES[category][key])
            
            # Add modality specific references
            modality = analysis.study.modality.code
            
            # Analyze findings/labels for keywords to match topics
            labels = [(_normalize_abnormality_label(a) or '').lower() for a in (analysis.abnormalities_detected or [])]
            finding_text = (analysis.findings or '').lower()
            
            # --- NEURORADIOLOGY ---
            if modality in ['CT', 'MR'] and ('brain' in str(analysis.study.body_part).lower() or 'head' in str(analysis.study.body_part).lower()):
                add_refs_for_key('neuroradiology', 'default')
                if any('stroke' in l for l in labels) or 'stroke' in finding_text:
                     add_refs_for_key('neuroradiology', 'stroke')
                if any('hemorrhage' in l for l in labels) or 'bleed' in finding_text:
                     add_refs_for_key('neuroradiology', 'hemorrhage')
                if any('tumor' in l for l in labels) or 'mass' in finding_text:
                     add_refs_for_key('neuroradiology', 'tumor')
            
            # --- CHEST ---
            elif modality in ['CT', 'XR', 'CR'] and ('chest' in str(analysis.study.body_part).lower() or 'lung' in str(analysis.study.body_part).lower()):
                 add_refs_for_key('chest', 'default')
                 if any('pneumonia' in l for l in labels) or 'consolidation' in finding_text:
                      add_refs_for_key('chest', 'pneumonia')
                 if any('pneumothorax' in l for l in labels):
                      add_refs_for_key('chest', 'pneumothorax')

            # --- MSK ---
            elif 'knee' in str(analysis.study.body_part).lower() or 'spine' in str(analysis.study.body_part).lower() or 'shoulder' in str(analysis.study.body_part).lower():
                add_refs_for_key('msk', 'default')
                if any('fracture' in l for l in labels):
                    add_refs_for_key('msk', 'fracture')
            
            else:
                 add_refs_for_key('general', 'default')

            # Add emergency references if urgent
            if triage.get('triage_level') == 'urgent':
                add_refs_for_key('emergency', 'default')
                
            # Limit to unique entries (dedupe by title+topic)
            seen = set()
            unique_suggested_refs = []
            for r in suggested_refs:
                key = f"{r['title']}:{r['topic']}"
                if key not in seen:
                    seen.add(key)
                    unique_suggested_refs.append(r)

            measurements['reference_suggestions'] = unique_suggested_refs
            
        except Exception:
            pass
            
        analysis.measurements = measurements
        analysis.save(update_fields=['measurements'])
    except Exception:
        pass

    # Upgrade study priority and notify if we actually upgraded.
    upgraded = _upgrade_study_priority(analysis.study, triage.get('triage_level', 'normal'))
    if upgraded and triage.get('flagged'):
        _notify_ai_triage(analysis, triage)


def simulate_ai_analysis(analysis):
    """Heavier inference if available; otherwise safe simulation."""
    modality = analysis.study.modality.code
    # Heavier text classification demo for AI summary confidence, if transformers available
    confidence = 0.85
    if AutoTokenizer and AutoModelForSequenceClassification:
        try:
            # Lightweight sentiment-like proxy to modulate confidence
            model_name = 'distilbert-base-uncased-finetuned-sst-2-english'
            tokenizer = AutoTokenizer.from_pretrained(model_name)
            model = AutoModelForSequenceClassification.from_pretrained(model_name)
            text = f"Preliminary {modality} analysis"
            inputs = tokenizer(text, return_tensors='pt')
            outputs = model(**inputs)
            scores = outputs.logits.softmax(dim=-1).detach().numpy()[0]
            confidence = float(scores.max()) * 0.2 + 0.8  # keep range ~0.8-1.0
        except Exception:
            confidence = 0.88
    # Optional ONNX path could go here for imaging if an .onnx exists; skip unless file provided
    time.sleep(2)

    # Deterministic “demo triage” abnormalities for smoke/demo environments.
    # Real deployments should replace this with actual model inference outputs.
    acc = (getattr(analysis.study, 'accession_number', '') or '').encode('utf-8')
    h = int(hashlib.md5(acc or b'0').hexdigest(), 16)
    clin = (getattr(analysis.study, 'clinical_info', '') or '').lower()

    if modality == 'CT':
        findings = "No acute intracranial abnormality. Brain parenchyma appears normal."
        abnormalities = []
        if 'trauma' in clin or 'fall' in clin or 'mvc' in clin or (h % 20 == 4):
            abnormalities = [{'label': 'Trauma context', 'severity_hint': 'urgent'}, {'label': 'Skull fracture suspicion', 'severity_hint': 'urgent'}]
            findings = "Trauma context with possible skull fracture; urgent review recommended."
        elif 'stroke' in clin or (h % 20 == 1):
            abnormalities = [{'label': 'Ischemic stroke suspicion', 'severity_hint': 'urgent'}]
            findings = "Findings suspicious for acute ischemic stroke; urgent clinical correlation recommended."
        elif 'hemorrhage' in clin or (h % 20 == 0):
            abnormalities = [{'label': 'Intracranial hemorrhage suspicion', 'severity_hint': 'urgent'}]
            findings = "Possible intracranial hemorrhage; urgent review recommended."
        elif 'mass' in clin or 'tumor' in clin or (h % 20 == 5):
            abnormalities = [{'label': 'Intracranial mass/lesion suspicion', 'severity_hint': 'high'}]
            findings = "Possible intracranial mass/lesion; recommend expedited review and correlation."
        elif (h % 20 == 2):
            abnormalities = [{'label': 'Mass effect / edema suspicion', 'severity_hint': 'high'}]
            findings = "Possible mass effect/edema; recommend expedited review."
        measurements = {"brain_volume": "1450 mL", "ventricle_size": "normal"}
    elif modality == 'MR':
        findings = "Normal brain MRI. No evidence of acute infarction or hemorrhage."
        abnormalities = []
        if 'ms' in clin or (h % 25 == 3):
            abnormalities = [{'label': 'Demyelinating lesions suspicion', 'severity_hint': 'high'}]
            findings = "Possible demyelinating lesions; correlate clinically and review sequences."
        measurements = {"lesion_count": 0, "white_matter": "normal"}
    elif modality == 'XR':
        findings = "Chest X-ray shows clear lungs. Heart size is normal."
        abnormalities = []
        if 'pneumothorax' in clin or (h % 15 == 0):
            abnormalities = [{'label': 'Pneumothorax suspicion', 'severity_hint': 'urgent'}]
            findings = "Possible pneumothorax; urgent review recommended."
        elif 'pneumonia' in clin or (h % 15 == 1):
            abnormalities = [{'label': 'Pneumonia / consolidation suspicion', 'severity_hint': 'high'}]
            findings = "Possible consolidation/pneumonia; recommend review."
        measurements = {"heart_size": "normal", "lung_fields": "clear"}
    else:
        findings = "Study reviewed by AI. No acute abnormalities detected."
        abnormalities = []
        measurements = {}

    # Calibrate confidence for demo cases.
    if abnormalities:
        confidence = 0.75 + ((h % 23) / 100.0)  # ~0.75-0.98
    else:
        confidence = min(confidence, 0.9)

    return {
        'findings': findings,
        'abnormalities': abnormalities,
        'confidence': confidence,
        'measurements': measurements
    }

def generate_report_content(study, analyses, template):
    """Generate report content from AI analyses"""
    # Aggregate findings from all analyses
    all_findings = []
    all_abnormalities = []
    confidence_scores = []
    reference_suggestions = []
    online_references = []
    
    for analysis in analyses:
        if analysis.findings:
            all_findings.append(f"[{analysis.ai_model.name}] {analysis.findings}")
        if analysis.abnormalities_detected:
            all_abnormalities.extend(analysis.abnormalities_detected)
        if analysis.confidence_score:
            confidence_scores.append(analysis.confidence_score)
        if analysis.measurements:
             if 'reference_suggestions' in analysis.measurements:
                reference_suggestions.extend(analysis.measurements['reference_suggestions'])
             if 'online_references' in analysis.measurements:
                online_references.extend(analysis.measurements['online_references'])
    
    # Calculate overall confidence
    overall_confidence = np.mean(confidence_scores) if confidence_scores else 0.5
    
    # Generate findings section
    findings_text = template.findings_template.format(
        patient_name=study.patient.full_name,
        study_date=study.study_date.strftime('%Y-%m-%d'),
        modality=study.modality.name,
        findings='; '.join(all_findings) if all_findings else 'No significant findings detected.'
    )
    
    # Generate impression
    if all_abnormalities:
        impression_text = f"Abnormalities detected: {', '.join([str(a) for a in all_abnormalities])}"
    else:
        impression_text = "No acute abnormalities detected by AI analysis."
    
    # Generate recommendations
    recommendations_text = template.recommendations_template or "Recommend correlation with clinical findings."
    
    # Add references to report if available
    research_nudge = ("Note: This AI-generated summary is for preliminary support only. "
                      "Please review images directly, correlate clinically.")
    
    # Format Book References with Topics
    if reference_suggestions:
        # Dedupe dicts by title+topic
        seen = set()
        unique_refs = []
        for r in reference_suggestions:
            if isinstance(r, dict):
                key = f"{r.get('title')}:{r.get('topic')}"
                if key not in seen:
                    seen.add(key)
                    unique_refs.append(f"{r.get('title')} (Topic: {r.get('topic')})")
            elif isinstance(r, str):
                 if r not in seen:
                    seen.add(r)
                    unique_refs.append(r)
        
        if unique_refs:
            research_nudge += "\n\nSuggested Medical Textbooks:\n" + "\n".join([f"- {ref}" for ref in unique_refs[:5]])

    # Format Online References (Real-time)
    if online_references:
         # Dedupe
         seen_urls = set()
         unique_online = []
         for r in online_references:
             if r.get('url') not in seen_urls:
                 seen_urls.add(r.get('url'))
                 unique_online.append(f"{r.get('title')} [{r.get('source')}]")
         
         if unique_online:
            research_nudge += "\n\nRelated Online Resources:\n" + "\n".join([f"- {ref}" for ref in unique_online[:5]])
    
    return {
        'findings': findings_text + "\n\n" + research_nudge,
        'impression': impression_text,
        'recommendations': recommendations_text,
        'confidence': overall_confidence
    }


@login_required
@csrf_exempt
def api_medical_references(request):
    """
    Provide curated external references based on query keywords (e.g., suspected finding/body part/modality).
    Returns titles and URLs from public reputable sources where possible.
    """
    try:
        query = request.GET.get('q', '').strip()
        if not query:
            return JsonResponse({'success': False, 'error': 'Missing query parameter q'}, status=400)
        
        # Check permissions for real-time fetch
        if not is_admin_or_radiologist(request.user):
             return JsonResponse({'success': False, 'error': 'Permission denied'}, status=403)

        # Use shared helper
        results = _get_online_references([query], max_results=10)

        return JsonResponse({
            'success': True,
            'query': query,
            'references': results
        })
    except Exception as e:
        return JsonResponse({'success': False, 'error': str(e)}, status=500)
